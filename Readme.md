# DUCK-Net for Skin Lesion Segmentation

This repository contains the code and models used in our study:  
**"Applying and Adapting DUCK-Net for Skin Lesion Segmentation"**  
ğŸ“„ *Authors*: Thoi-Toan Nguyen Dang et al.  
ğŸ“… *Date*: July 2025

## ğŸ“ Abstract
We adapt DUCK-Net, a lightweight convolutional neural network originally designed for polyp segmentation, to the task of skin lesion segmentation using the ISIC-2016 dataset. We also propose two compressed variantsâ€”DUCK-Net-Lite and DUCK-Net-Tinyâ€”to explore the accuracy-efficiency tradeoff for deployment in resource-constrained environments.

Our best model achieves:
- **Dice Coefficient**: 92.52%
- **IoU**: 86.08%
- Trained **from scratch**, without pretrained weights.

## ğŸ“Š Key Contributions
- âœ… Adapted DUCK-Net to ISIC-2016 without pretrained weights.
- ğŸª¶ Proposed DUCK-Net-Lite with 45% fewer parameters and minimal accuracy loss.
- ğŸ“‰ Conducted ablation studies on block structure and depth.
- âš™ï¸ Implemented with TensorFlow 2.11 and Albumentations for online augmentation.


## ğŸ“‚ Project Structure
```
ğŸ“ DUCK-Net-Lite/             # Main implementation of DUCK-Net-Lite
ğŸ“ DUCK-Net-Tiny/             # Depth-reduced version (DUCK-Net-Tiny)
ğŸ“ DUCK-Net-Ablation-Study/   # Experiments replacing DUCK blocks with Conv
ğŸ“ Paper                      # Contains the full PDF paper
â”œâ”€â”€ README.md                  # Project documentation
```


## ğŸ“„ Paper Access

ğŸ§¾ [Full Paper (PDF)](https://github.com/yournames762/Lite/blob/main/Paper/Applying%20and%20Adapting%20DUCK-Net%20for%20Skin%20Lesion%20Segmentation.pdf)

> âš ï¸ **Note:** This paper is a working draft submitted for review. It has not been peer-reviewed or officially published yet. Please do not cite or redistribute without permission.

## ğŸ“Œ Citation

This work builds on [DUCK-Net](https://doi.org/10.1038/s41598-023-36940-5) proposed by Dumitru et al. (2023), originally designed for polyp segmentation. We adapt and compress the architecture for skin lesion segmentation on ISIC-2016.
